{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Songs on Spotify - Part 1: Distance Based Search\n",
    "\n",
    "The first part of this tutorial series demonstrates the traditional way of extracting features from the audio content, training a classifier and predicting results. Because we do not have access to the raw audio content, we cannot extract features ourselves. Fortunately, Spotify is so generious to provide extracted features via their API. Those are just low-level audio features, but they are more than any other streaming music service provide - so Kudos to Spotify for this API! To download the features from the Spotify API you need to apply for a valid client ID. Please follow the steps on the Github page to apply for such an ID.\n",
    "\n",
    "\n",
    "## Part 1 - Overview\n",
    "\n",
    "1. Introductions & Requirements\n",
    "2. Accessing the Spotify API\n",
    "3. Loading data\n",
    "4. Preprocess data\n",
    "5. Define the Similarity Model\n",
    "6. Optimize the Model\n",
    "7. Evaluate the Models\n",
    "\n",
    "\n",
    "# Short Introduction to Music Similarity Retrieval\n",
    "\n",
    "The objective of Music Similarity estimation or retrieval is to estimate the notion of similarity between two given tracks. A central part of such an approaches is the definition of a measure for similarity which is further affected by the approach taken to extract the relevant information. One approach is to analyze contextual data such as user generated listening behaviour data (e.g. play/skip-counts, user-tags, ratings, etc.). The approach followed by this tutorial is based on the music content itself and largely focuses on the notion of *acoustic similarity*. Music features are extracted from the audio content. The resulting music descriptors are high-dimensional numeric vectors and the accumulation of all feature vectors of a collection forms a vector-space. The general principle of content based similarity estimations is based on the assumption that numerical differences are an expression of perceptual dissimilarity. Different metrics such as the Manhattan (L1) or the Euclidean Distance (L2) or non-metric similarity functions such as the Kullback-Leibler divergence are used to estimate the numerical similarity of the feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "Please follow the instructions on the tutorial's Github page (https://github.com/slychief/tutorials/tree/master/spotify_similarity_search) to install the following dependencies to run this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.488000Z",
     "start_time": "2017-08-24T10:20:32.483000Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# numeric and scientific processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spotipy**\n",
    "\n",
    "Spotipy is a thin client library for the Spotify Web API.\n",
    "\n",
    "https://github.com/plamere/spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the following two variables according the credentials you received from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:33.260000Z",
     "start_time": "2017-08-24T10:20:33.256000Z"
    }
   },
   "outputs": [],
   "source": [
    "SPOTIFY_USER = \"\"\n",
    "\n",
    "os.environ[\"SPOTIPY_CLIENT_ID\"]     = \"\"\n",
    "os.environ[\"SPOTIPY_CLIENT_SECRET\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get the following message:\n",
    "\n",
    "    User authentication requires interaction with your\n",
    "    web browser. Once you enter your credentials and\n",
    "    give authorization, you will be redirected to\n",
    "    a url.  Paste that url you were directed to to\n",
    "    complete the authorization.\n",
    "\n",
    "    Opened https://accounts.spotify.com/authorize?scope=playlist-modify-public&redirect_uri=ht...\n",
    "    \n",
    "\n",
    "You need to authenticate your browser session. Follow the link and log in to Spotify. After login, you will be redirected to http://localhost/?code=... Copy the entire URL and paste it to the prompted textbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:54.045000Z",
     "start_time": "2017-08-24T10:20:34.076000Z"
    }
   },
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(SPOTIFY_USER, \n",
    "                                   \"playlist-modify-public\", \n",
    "                                   redirect_uri=\"http://localhost/\")\n",
    "\n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "Before we can train our models we first have to get some data.\n",
    "\n",
    "## Download Echonest Features from Spotify\n",
    "\n",
    "We use spotipy to access the Spotify API and to download metadata and audio features of Spotify tracks. The following list provides a selection of Spotify playlists of various music genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = [\n",
    "    \n",
    "     {\"name\": \"clubbeats\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXbX3zSzB4MO0\"},\n",
    "     {\"name\": \"softpop\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWTwnEm1IYyoj\"},\n",
    "     {\"name\": \"electropop\",   \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4uPi2roRUwU\"},\n",
    "     {\"name\": \"rockclassics\", \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXRqgorJj26U\"},\n",
    "     {\"name\": \"rockhymns\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX4vth7idTQch\"},\n",
    "     {\"name\": \"soft_rock\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX6xOPeSOGone\"},\n",
    "     {\"name\": \"metalcore\",    \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWXIcbzpLauPS\"}, \n",
    "     {\"name\": \"metal\",        \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWWOaP4H0w5b0\"},\n",
    "     {\"name\": \"classic_metal\",\"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX2LTcinqsO68\"},\n",
    "     {\"name\": \"grunge\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DX11ghcIxjcjE\"},\n",
    "     {\"name\": \"hiphop\",       \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DWVdgXTbYm2r0\"},\n",
    "     {\"name\": \"poppunk\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXa9wYJr1oMFq\"},\n",
    "     {\"name\": \"classic\",      \"uri\": \"spotify:user:spotify:playlist:37i9dQZF1DXcN1fAVSf7CR\"}\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Playlist meta-data\n",
    "\n",
    "Insted of writing one big loop to download the data, I decided to split it into separate more comprehensible steps.\n",
    "\n",
    "The Spotify API does not return infinite elements, but requires batch processing. The largest batch size is 100 items such as tracks, artists or albums. As a first step we get relevant meta-data for the supplied playlists. Especially the *num_track* property is conveniant for the further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_metadata(spotify_client, playlists):\n",
    "\n",
    "    for playlist in playlists:\n",
    "\n",
    "        # get user and playlist_id from uri\n",
    "        (_,_,user,_,playlist_id) = playlist[\"uri\"].split(\":\")\n",
    "\n",
    "        # retrieve playlist metadat from Spotify\n",
    "        playlist_metadata = spotify_client.user_playlist(user        = user,\n",
    "                                                         playlist_id = playlist_id)\n",
    "\n",
    "        # extract relevant information\n",
    "        playlist[\"user\"]        = user\n",
    "        playlist[\"playlist_id\"] = playlist_id\n",
    "        playlist[\"num_tracks\"]  = playlist_metadata[\"tracks\"][\"total\"]\n",
    "\n",
    "        # initialize fields for further processing\n",
    "        playlist[\"track_ids\"]   = []\n",
    "        \n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = get_playlist_metadata(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of our dataset**\n",
    "\n",
    "Now we can already estimate the approximate size of our data-set. The set might contain duplicate tracks from overlapping playlists. Those are removed later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feaa01b4780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playlist_sizes = pd.DataFrame(data  = [playlist[\"num_tracks\"] for playlist in playlists],\n",
    "                              index = [playlist[\"name\"] for playlist in playlists])\n",
    "\n",
    "playlist_sizes.sort_values(0,ascending=False).plot(kind='bar', figsize=(10,4), legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of tracks (including duplicates - will be removed later on)\n",
    "int(playlist_sizes.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get track-ids of all playlist entries\n",
    "\n",
    "To download meta- and feature-data for tracks, we need to fetch the playlist entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_ids(sp, playlists):\n",
    "\n",
    "    # max Spotify batch size\n",
    "    batch_size = 100\n",
    "\n",
    "    # retrieve tracks for each playlist\n",
    "    for playlist in playlists:\n",
    "\n",
    "        # batch processing\n",
    "        for offset in np.arange(0, playlist[\"num_tracks\"], batch_size):\n",
    "\n",
    "            limit = np.min([batch_size, playlist[\"num_tracks\"] - offset])\n",
    "\n",
    "            playlist_entries = sp.user_playlist_tracks(user        = playlist[\"user\"],\n",
    "                                                       playlist_id = playlist[\"playlist_id\"], \n",
    "                                                       limit       = limit, \n",
    "                                                       offset      = offset,\n",
    "                                                       fields      = [\"items\"])\n",
    "\n",
    "            playlist[\"track_ids\"].extend([entry[\"track\"][\"id\"] for entry in playlist_entries[\"items\"]])\n",
    "            \n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = get_track_ids(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data and features from Spotify\n",
    "\n",
    "Now it's time to download the dat for our tracks.\n",
    "\n",
    "The features provided by the Spotify API were extracted using the *Echonest Analyzer*. This is a music audio analysis tool developed by the music analysis company the Echonest which was aquired by Spotify in 2014. Music metadata returned by the Analyzer includes artist information (name, user applied tags including weights and term frequencies, a list of similar artists), album information (name, year) and song information (title). Additionally a set of identifiers is provided that can be used to access complimentary metadata repositories (e.g. musicbrainz\\footnote{http://musicbrainz.org}, playme\\footnote{http://www.playme.com},7digital)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching with joblib\n",
    "\n",
    "We will use caching to locally store retrieved data. This is on the one hand a requirement of the API and on the other it speeds up processing when we reload the notebook. *joblib* is a convenient library which simplifies caching.\n",
    "\n",
    "*Update the cachdir to an appropriate path in the following cell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:20:32.875000Z",
     "start_time": "2017-08-24T10:20:32.870000Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(cachedir='/home/schindler/tmp/spotify/', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method retrieves meta-data, sequential features such as *MFCCs* and *Chroma*, and track-level features such as *Dancability*. The *@memory.cache* annotation tells *joblib* to persist all return values for the supplied parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def get_spotify_data(track_id):\n",
    "    \n",
    "    # meta-data\n",
    "    track_metadata      = sp.track(track_id)\n",
    "    album_metadata      = sp.album(track_metadata[\"album\"][\"id\"])\n",
    "    artist_metadata     = sp.artist(track_metadata[\"artists\"][0][\"id\"])\n",
    "    \n",
    "    # feature-data\n",
    "    sequential_features = sp.audio_analysis(track_id)\n",
    "    trackbased_features = sp.audio_features([track_id])\n",
    "    \n",
    "    return track_metadata, album_metadata, artist_metadata, sequential_features, trackbased_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieving data for all tracks**\n",
    "\n",
    "The following loop downloads meta- and feature-data for all tracks. The *processed_track_ids* list is used to avoid duplicated entries. Be aware that downloading a lot of tracks could take some time. Processing 1.000 tracks may take about 15 to 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_track_data(sp, playlists):\n",
    "\n",
    "    num_tracks_total = np.sum([playlist[\"num_tracks\"] for playlist in playlists])\n",
    "    \n",
    "    pbar = progressbar.ProgressBar(max_value=num_tracks_total)\n",
    "    pbar.start()\n",
    "\n",
    "    raw_track_data      = []\n",
    "    processed_track_ids = []\n",
    "\n",
    "    for playlist in playlists:\n",
    "\n",
    "        for track_id in playlist[\"track_ids\"]:\n",
    "\n",
    "            try:\n",
    "                # avoid duplicates in the data-set\n",
    "                if track_id not in processed_track_ids:\n",
    "\n",
    "                    # retrieve data from Spotify\n",
    "                    spotify_data = get_spotify_data(track_id)\n",
    "\n",
    "                    raw_track_data.append([playlist[\"name\"], spotify_data])\n",
    "                    processed_track_ids.append(track_id)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "            pbar.update(len(raw_track_data))\n",
    "            \n",
    "    return raw_track_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98% (1059 of 1078) |#################### | Elapsed Time: 0:02:12 ETA:  0:00:03"
     ]
    }
   ],
   "source": [
    "raw_track_data = download_track_data(sp, playlists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data\n",
    "\n",
    "Currently we only have a list of raw data-objects retrieved from the Spotify API. We need to transform this information to a more structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Meta-data\n",
    "\n",
    "First we aggregate the meta-data. All relevant information is stored in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_metadata(raw_track_data):\n",
    "\n",
    "    metadata = []\n",
    "\n",
    "    for playlist_name, spotify_data in raw_track_data:\n",
    "\n",
    "        track_metadata, album_metadata, artist_metadata, _, _ = spotify_data\n",
    "\n",
    "        # get year of album release\n",
    "        release_date = album_metadata[\"release_date\"]\n",
    "\n",
    "        if album_metadata[\"release_date_precision\"] != \"year\":\n",
    "            release_date = release_date.split(\"-\")[0]\n",
    "\n",
    "        # assamble metadata\n",
    "        metadata.append([track_metadata[\"id\"],\n",
    "                         artist_metadata[\"name\"], \n",
    "                         track_metadata[\"name\"], \n",
    "                         album_metadata[\"name\"],\n",
    "                         album_metadata[\"label\"],\n",
    "                         track_metadata[\"duration_ms\"],\n",
    "                         track_metadata[\"popularity\"],\n",
    "                         release_date,\n",
    "                         artist_metadata[\"genres\"], \n",
    "                         playlist_name])\n",
    "\n",
    "    metadata = pd.DataFrame(metadata, columns=[\"track_id\", \"artist_name\", \"title\", \"album_name\", \n",
    "                                               \"label\", \"duration\", \"popularity\",  \"year\",  \"genres\", \n",
    "                                               \"playlist\"])\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = aggregate_metadata(raw_track_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here an example of the aggregated meta-data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>6T8cJz5lAqGer9GUHGyelE</td>\n",
       "      <td>Drake</td>\n",
       "      <td>God's Plan</td>\n",
       "      <td>Scary Hours</td>\n",
       "      <td>Universal Music Group</td>\n",
       "      <td>198960</td>\n",
       "      <td>100</td>\n",
       "      <td>2018</td>\n",
       "      <td>[canadian pop, hip hop, pop rap, rap]</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6tHWl8ows5JOZq9Yfaqn3M</td>\n",
       "      <td>Bazzi</td>\n",
       "      <td>Mine</td>\n",
       "      <td>Mine</td>\n",
       "      <td>ZZZ Entertainment</td>\n",
       "      <td>133994</td>\n",
       "      <td>99</td>\n",
       "      <td>2017</td>\n",
       "      <td>[]</td>\n",
       "      <td>softpop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>4qKcDkK6siZ7Jp1Jb4m0aL</td>\n",
       "      <td>BlocBoy JB</td>\n",
       "      <td>Look Alive (feat. Drake)</td>\n",
       "      <td>Look Alive (feat. Drake)</td>\n",
       "      <td>OVO Sound/Warner Bros.</td>\n",
       "      <td>181263</td>\n",
       "      <td>98</td>\n",
       "      <td>2018</td>\n",
       "      <td>[rap, southern hip hop, trap music]</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7wrDRQgHlvDnimrRHfQZxt</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Psycho (feat. Ty Dolla $ign)</td>\n",
       "      <td>Psycho (feat. Ty Dolla $ign)</td>\n",
       "      <td>Universal Music Group</td>\n",
       "      <td>220880</td>\n",
       "      <td>95</td>\n",
       "      <td>2018</td>\n",
       "      <td>[pop, rap]</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>35ieKju5aLWFN5UgfJ27mL</td>\n",
       "      <td>XXXTENTACION</td>\n",
       "      <td>SAD!</td>\n",
       "      <td>SAD!</td>\n",
       "      <td>Bad Vibes Forever, LLC</td>\n",
       "      <td>166568</td>\n",
       "      <td>94</td>\n",
       "      <td>2018</td>\n",
       "      <td>[]</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   track_id   artist_name                         title  \\\n",
       "864  6T8cJz5lAqGer9GUHGyelE         Drake                    God's Plan   \n",
       "105  6tHWl8ows5JOZq9Yfaqn3M         Bazzi                          Mine   \n",
       "863  4qKcDkK6siZ7Jp1Jb4m0aL    BlocBoy JB      Look Alive (feat. Drake)   \n",
       "865  7wrDRQgHlvDnimrRHfQZxt   Post Malone  Psycho (feat. Ty Dolla $ign)   \n",
       "868  35ieKju5aLWFN5UgfJ27mL  XXXTENTACION                          SAD!   \n",
       "\n",
       "                       album_name                   label  duration  \\\n",
       "864                   Scary Hours   Universal Music Group    198960   \n",
       "105                          Mine       ZZZ Entertainment    133994   \n",
       "863      Look Alive (feat. Drake)  OVO Sound/Warner Bros.    181263   \n",
       "865  Psycho (feat. Ty Dolla $ign)   Universal Music Group    220880   \n",
       "868                          SAD!  Bad Vibes Forever, LLC    166568   \n",
       "\n",
       "     popularity  year                                 genres playlist  \n",
       "864         100  2018  [canadian pop, hip hop, pop rap, rap]   hiphop  \n",
       "105          99  2017                                     []  softpop  \n",
       "863          98  2018    [rap, southern hip hop, trap music]   hiphop  \n",
       "865          95  2018                             [pop, rap]   hiphop  \n",
       "868          94  2018                                     []   hiphop  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.sort_values(\"popularity\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Feature Data\n",
    "\n",
    "\n",
    "Further information provided by the Spotify API is based on audio signal analysis. Two major sets of audio features are provided describing timbre and pitch information of the corresponding music track. The features are extracted using onset detection to segment the audio based on music events. These *Segments* are described as sound entities that are relative uniform in timbre and harmony and are the basis for further feature extraction. For each *Segment* the following features are derived from musical audio signals:\n",
    "\n",
    "* **Segments Timbre** are casually described as MFCC-like features. A 12 dimensional vector with unbounded values centered around 0 representing a high level abstraction of the spectral surface.\n",
    "* **Segments Pitches** are casually described as Chroma-like features. A normalized 12 dimensional vector ranging from 0 to 1 corresponding to the 12 pitch classes C, C#, to B.\n",
    "* **Segments Loudness Max** represents the peak loudness value within each segment.\n",
    "* **Segments Loudness Max Time** describes the offset within the segment of the point of maximum loudness.\n",
    "* **Segments Start** provide start time information of each segment/onset.\n",
    "\n",
    "Additionally a set of high-level features provided on a global track-level:\n",
    "\n",
    "* **Tempo** measured in beats per minute\n",
    "* **Time Signature** three or four quater stroke\n",
    "* **Danceability** a value between 0 and 1 measuring of how danceable this song is \n",
    "* **Energy** a value between 0 and 1 measuring the perceived energy of a song\n",
    "* **acousticness** does the track only use acoustic instruments?\n",
    "* **danceability** can you dance to this track?\n",
    "* **instrumentalnes** is there somebody singing?\n",
    "* **liveness** live or studio version?\n",
    "* **speechiness** rap music or singing?\n",
    "* **valence** aggressive or calm?\n",
    "\n",
    "I performed a detailed evaluation of the Echonest Feature-sets and how to effectively aggregate the provided information for Music Information Retrieval Experiments on the Million Song Dataset. The results are published in the following article:\n",
    "\n",
    "* *Alexander Schindler and Andreas Rauber. [Capturing the temporal domain in echonest features for improved classification effectiveness](http://www.ifs.tuwien.ac.at/%7Eschindler/pubs/AMR2012.pdf). In Adaptive Multimedia Retrieval, Lecture Notes in Computer Science, Copenhagen, Denmark, October 24-25 2012. Springer.*\n",
    "\n",
    "### Single Vector Representation\n",
    "\n",
    "The simlarity retrieval approach presented in this tutorial is based on a vector-space model where each track is represented of a single fixed-length feature vector. The segment-based features provided by the Spotify API are lists of feature vectors of varying lengths. Thus, these features need to be aggregated into a single feature vector. The following function describes a simple approach to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:58:50.844000Z",
     "start_time": "2017-08-24T12:58:50.830000Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_features(seq_data, track_data, metadata, with_year=False, with_popularity=False):\n",
    "\n",
    "    calc_statistical_moments = lambda x: np.concatenate([x.mean(axis=0), x.std(axis=0)])\n",
    "    \n",
    "    # sequential data\n",
    "    segments = seq_data[\"segments\"]\n",
    "    sl       = len(segments)\n",
    "    \n",
    "    # MFCCs - 24 dimensions\n",
    "    mfcc              = np.array([s[\"timbre\"] for s in segments])\n",
    "    mfcc              = calc_statistical_moments(mfcc)\n",
    "    \n",
    "    # Chroma / pitch classes - 24 dimensions\n",
    "    chroma            = np.array([s[\"pitches\"] for s in segments])\n",
    "    chroma            = calc_statistical_moments(chroma)\n",
    "    \n",
    "    # maximum loudness values per segment - 2 dimensions\n",
    "    loudness_max      = np.array([s[\"loudness_max\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_max      = calc_statistical_moments(loudness_max)\n",
    "    \n",
    "    # offset of max loudness value within segment - 2 dimensions\n",
    "    loudness_start    = np.array([s[\"loudness_start\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_start    = calc_statistical_moments(loudness_start)\n",
    "    \n",
    "    # length of max loudness values within segment - 2 dimensions\n",
    "    loudness_max_time = np.array([s[\"loudness_max_time\"] for s in segments]).reshape((sl,1))\n",
    "    loudness_max_time = calc_statistical_moments(loudness_max_time)\n",
    "    \n",
    "    # length of segment - 2 dimensions\n",
    "    duration          = np.array([s[\"duration\"] for s in segments]).reshape((sl,1))\n",
    "    duration          = calc_statistical_moments(duration)\n",
    "    \n",
    "    # confidence of segment boundary detection - 2 dimensions\n",
    "    confidence        = np.array([s[\"confidence\"] for s in segments]).reshape((sl,1))\n",
    "    confidence        = calc_statistical_moments(confidence)\n",
    "    \n",
    "    # concatenate sequential features\n",
    "    sequential_features = np.concatenate([mfcc, chroma, loudness_max, loudness_start, \n",
    "                                          loudness_max_time, duration, confidence], axis=0)\n",
    "    \n",
    "    # track-based data\n",
    "    track_features = [track_data[0][\"acousticness\"],     # acoustic or not?\n",
    "                      track_data[0][\"danceability\"],     # danceable?\n",
    "                      track_data[0][\"energy\"],           # energetic or calm?\n",
    "                      track_data[0][\"instrumentalness\"], # is somebody singing?\n",
    "                      track_data[0][\"liveness\"],         # live or studio?\n",
    "                      track_data[0][\"speechiness\"],      # rap or singing?\n",
    "                      track_data[0][\"tempo\"],            # slow or fast?\n",
    "                      track_data[0][\"time_signature\"],   # 3/4, 4/4, 6/8, etc.\n",
    "                      track_data[0][\"valence\"]]          # happy or sad?\n",
    "    \n",
    "    if with_year:\n",
    "        track_features.append(int(metadata[\"year\"]))\n",
    "        \n",
    "    if with_popularity:\n",
    "        track_features.append(int(metadata[\"popularity\"]))\n",
    "        \n",
    "    \n",
    "    return np.concatenate([sequential_features, track_features], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afgregate all features of the downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_featuredata(raw_track_data):\n",
    "\n",
    "    feature_data = []\n",
    "\n",
    "    for i, (_, spotify_data) in enumerate(raw_track_data):\n",
    "\n",
    "        _, _, _, f_sequential, f_trackbased = spotify_data\n",
    "\n",
    "        feature_vec = aggregate_features(f_sequential, \n",
    "                                         f_trackbased, \n",
    "                                         metadata.iloc[i], \n",
    "                                         with_year       = True, \n",
    "                                         with_popularity = True)    \n",
    "\n",
    "        feature_data.append(feature_vec)\n",
    "\n",
    "    return np.asarray(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T10:38:34.716000Z",
     "start_time": "2017-08-24T10:38:34.703000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_data.shape: (1060, 69)\n"
     ]
    }
   ],
   "source": [
    "feature_data = aggregate_featuredata(raw_track_data)\n",
    "\n",
    "print(\"feature_data.shape:\", feature_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize feature data\n",
    "\n",
    "The feature vectors are composed of differnt feature-sets. All of them with different value ranges. While features such as Acousticness and Danceability are scaled between 0 and 1, the BPM values of the tempo feature ranges around 120 or higher. We apply Standard Score or Zero Mean and Unit Variance normalization to uniformly scale the value ranges of the features.\n",
    "\n",
    "$$\n",
    "z = {x- \\mu \\over \\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize sequential_features\n",
    "feature_data -= feature_data.mean(axis=0)\n",
    "feature_data /= feature_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Similarities\n",
    "\n",
    "This section describes the fundamentals of the content-based audio similarity search approach followed in this tutorial. Audio features are descriptive numbers calculated from the audio spectrum of a track. A good example is the Spectral Centroid, which can be interpreted as the center of gravity of an audio recording. It describes the average frequency weighted by its intensity and distinguishes brighter from darker sounds. Such features are usually calculated for several intervals of a track and finally aggregated into a single vector representation. The latter step, which is a requirement for many machine/statistical learning tasks, is accomplished by calculating statistical measures such as mean, standard deviation, etc.\n",
    "\n",
    "In the following example, the Spectral Centroids of 10 different tracks are provided using their mean and standard deviation aggregations. Thus, the Spectral Centroid feature(-set) is represented by a two-dimensional feature vector such as the following example:\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "\n",
    "In this example the center frequency is 1518 Hz and it deviates by 291 Hz. These numbers already describe the audio content and can be used to find similar tracks. The common approach to calcualte music similarity from audio content is based on vector difference. The assumption is, that similar audio feature-values correspond with similar audio content. Thus, feature vectors with smaller vector differences correspond to more similar tracks. The following data represents the extracted Spectral Centroids of our 10-tracks collection:\n",
    "\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "    1    1659.1988993873124    327.64811981777865\n",
    "    2    1507.4617047141264    340.8830079395701\n",
    "    3    1597.6019371942953    507.1007933367403\n",
    "    4    1498.8531206911534    288.3780838480238\n",
    "    5    535.5910732230583     89.90893994909047\n",
    "    6    2261.4032345595674    353.5971736260454\n",
    "    7    2331.881852844861     406.33517225264194\n",
    "    8    1868.690426450363     342.7489751514078\n",
    "    9    2204.6324484864085    328.94334883095553\n",
    "\n",
    "The tracks have unique identifiers and we are using the track with ID 5 to search for similar items. This step requires a similarity metric, which defines how the vector distance has to be calculated as a single numeric value. The most common choices are the Manhattan (L1) and Euclidean (L2) distance measures. The Euclidean Distance is the square root of the sum of squared differences of two vectors.\n",
    "To calculate the Euclidean Distance between track 5 and track 0:\n",
    "\n",
    "    ID   Mean                  Standard Deviation\n",
    "    0    1517.5993814237531    291.1855836731788\n",
    "    5    535.5910732230583     89.90893994909047\n",
    "\n",
    "we first compute the difference between the values of each vectors\n",
    "\n",
    "    982.008308           201.276644\n",
    "\n",
    "square them to get the absolute magnitude:\n",
    "\n",
    "    964340.317375        40512.287309\n",
    "\n",
    "and take the sum of these values:\n",
    "\n",
    "    1004852.6046840245\n",
    "\n",
    "Per definition the square root has to be calculated from the sum, but this step is normally skipped because it does not alter the ranking and is processing intensive. By calculating the distance for all items in the collection, we retrieve a list of distance values where the smaller distances correspond to more similar audio content and the higher values should sound more dissimilar.\n",
    "\n",
    "    ID   Distance\n",
    "    0    1004852.6046840245\n",
    "    1    1319014.4646621975\n",
    "    2    1007520.5071585375\n",
    "    3    1301916.1177259558\n",
    "    4    967263.7731724023\n",
    "    5    0.0\n",
    "    6    3047959.100796666\n",
    "    7    3326786.1254441254\n",
    "    8    1841081.968976167\n",
    "    9    2842836.5609704787\n",
    "\n",
    "To retrieve a ranked list of similar sounding tracks, the list of vector distances has to be ordered ascendingly.\n",
    "\n",
    "    ID   Distance\n",
    "    5    0.0\n",
    "    4    967263.7731724023\n",
    "    0    1004852.6046840245\n",
    "    2    1007520.5071585375\n",
    "    3    1301916.1177259558\n",
    "    1    1319014.4646621975\n",
    "    8    1841081.968976167\n",
    "    9    2842836.5609704787\n",
    "    6    3047959.100796666\n",
    "    7    3326786.1254441254\n",
    "\n",
    "This so called vector space model is predominant in content based multimedia retrieval. The most crucial and problematic part is feature crafting, meaning that in the case in which the extracted numbers do not describe the audio well enough, the vector based similarity will also fail to provide results that are perceived as similar.\n",
    "The described approach requires the availability of all feature vectors of all items of a collection. Thus, the feature vectors must be stored. No matter which retrieval approach (pre-calculated / indexed / on demand) will be chosen, all features will be required at a certain time. Given that the feature extraction is an computationally expensive task (in terms of processing resources and total time), the extracted features are stored and made accessible using a common data format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "\n",
    "In the final part of this tutorial we wil use the Euclidean Distance to calculate similarities between tracks. As mentioned above, the Euclidean Distance is a metric to calculate the distance between two vectors and thus is a function of dissimilarity. This means, vectors with smaller distance values are more similar than those with higher distances.\n",
    "\n",
    "$$\n",
    "d(p,q) = \\sqrt{\\sum_{i=1}^n (q_i-p_i)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucledian_distance(feature_space, query_vector):\n",
    "    \n",
    "    return np.sqrt(np.sum((feature_space - query_vector)**2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the rest of the tutorial we will use this song to demonstrate the results of the approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>637McrDyDQ9CffkFuZGRpq</td>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Dharma</td>\n",
       "      <td>206250</td>\n",
       "      <td>54</td>\n",
       "      <td>2017</td>\n",
       "      <td>[big room, deep big room, edm, electro house, ...</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  track_id artist_name    title album_name   label  duration  \\\n",
       "33  637McrDyDQ9CffkFuZGRpq       KSHMR  Kolkata    Kolkata  Dharma    206250   \n",
       "\n",
       "    popularity  year                                             genres  \\\n",
       "33          54  2017  [big room, deep big room, edm, electro house, ...   \n",
       "\n",
       "     playlist  \n",
       "33  clubbeats  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_track_idx = 33\n",
    "\n",
    "metadata.loc[[query_track_idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code implement the approach described above. First, the distances between the query vector and all other vectors of the collection are calculated. Then the distances are sorted ascnedingly to get the simlar tracks. Because the metric distance of identical vectors is 0, the top-most entry of the sorted list is always the query track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>JACKHAD</td>\n",
       "      <td>Get Money - Radio Edit</td>\n",
       "      <td>Get Money</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Calvin Logue</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>Warrior EP</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maeva Carter</td>\n",
       "      <td>Escape</td>\n",
       "      <td>Escape</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hardwell</td>\n",
       "      <td>Get Low</td>\n",
       "      <td>Get Low</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>James Hype</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>What So Not</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>2018</td>\n",
       "      <td>electropop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>The Offspring</td>\n",
       "      <td>Why Don't You Get A Job</td>\n",
       "      <td>Americana</td>\n",
       "      <td>1998</td>\n",
       "      <td>poppunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Parkway Drive</td>\n",
       "      <td>Wishing Wells</td>\n",
       "      <td>Wishing Wells</td>\n",
       "      <td>2018</td>\n",
       "      <td>metalcore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rave Radio</td>\n",
       "      <td>Turn Me Out - Radio Edit</td>\n",
       "      <td>Turn Me Out</td>\n",
       "      <td>2016</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>The Wild</td>\n",
       "      <td>Heaven Is A Place On Earth</td>\n",
       "      <td>Heaven Is A Place On Earth</td>\n",
       "      <td>2017</td>\n",
       "      <td>electropop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_name                                  title  \\\n",
       "33           KSHMR                                Kolkata   \n",
       "29         JACKHAD                 Get Money - Radio Edit   \n",
       "49    Calvin Logue                                Warrior   \n",
       "22    Maeva Carter                                 Escape   \n",
       "16        Hardwell                                Get Low   \n",
       "13      James Hype  More Than Friends (feat. Kelli-Leigh)   \n",
       "285    What So Not                              Beautiful   \n",
       "945  The Offspring                Why Don't You Get A Job   \n",
       "681  Parkway Drive                          Wishing Wells   \n",
       "11      Rave Radio               Turn Me Out - Radio Edit   \n",
       "311       The Wild             Heaven Is A Place On Earth   \n",
       "\n",
       "                                album_name  year    playlist  \n",
       "33                                 Kolkata  2017   clubbeats  \n",
       "29                               Get Money  2018   clubbeats  \n",
       "49                              Warrior EP  2018   clubbeats  \n",
       "22                                  Escape  2018   clubbeats  \n",
       "16                                 Get Low  2018   clubbeats  \n",
       "13   More Than Friends (feat. Kelli-Leigh)  2017   clubbeats  \n",
       "285                              Beautiful  2018  electropop  \n",
       "945                              Americana  1998     poppunk  \n",
       "681                          Wishing Wells  2018   metalcore  \n",
       "11                             Turn Me Out  2016   clubbeats  \n",
       "311             Heaven Is A Place On Earth  2017  electropop  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the distance between the query-vector and all others\n",
    "dist = eucledian_distance(feature_data, feature_data[query_track_idx])\n",
    "\n",
    "# sort the distances ascendingly - use sorted index\n",
    "sorted_idx = np.argsort(dist)\n",
    "\n",
    "# display top-10 results (first track = query track)\n",
    "display_cols = [\"artist_name\", \"title\", \"album_name\", \"year\", \"playlist\"]\n",
    "\n",
    "metadata.loc[sorted_idx[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Eucledian Distance\n",
    "\n",
    "The approach taken to combine the different feature-sets is refered to as early fusion. The problem with the approach described in the previous step is, that larger feature-sets dominate the calculated distance values. The aggregated MFCC and Chroma features have 24 dimensions each. Together they have more dimensions as the remaining features which are mostly single dimensional features. Thus, the distances are unequally dominated by the two feature sets.\n",
    "\n",
    "To avoid such a bias, we scale the feature-space such that feature-sets and single-value features have euqal the same weights and thus euqal influence on the resulting distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-set lengths and order\n",
    "featureset_lengths = [24, # mfcc\n",
    "                      24, # chroma\n",
    "                      2,  # loudness_max\n",
    "                      2,  # loudness_start\n",
    "                      2,  # loudness_max_time\n",
    "                      2,  # sequence length\n",
    "                      2,  # confidence\n",
    "                      1,  # acousticness\n",
    "                      1,  # danceability\n",
    "                      1,  # energy\n",
    "                      1,  # instrumentalness\n",
    "                      1,  # liveness\n",
    "                      1,  # speechiness\n",
    "                      1,  # tempo\n",
    "                      1,  # time_signature\n",
    "                      1,  # valence\n",
    "                      1,  # year\n",
    "                      1]  # popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_eucledian_distance(feature_space, query_vector):\n",
    "    \n",
    "    distances = (feature_space - query_vector)**2\n",
    "    \n",
    "    # feature_start_idx\n",
    "    start_idx = 0 \n",
    "    \n",
    "    # normalize distances\n",
    "    for sequence_length in featureset_lengths:\n",
    "        \n",
    "        # feature_stop_idx\n",
    "        stop_idx                         = start_idx + sequence_length\n",
    "        distances[:,start_idx:stop_idx] /= distances[:,start_idx:stop_idx].sum(axis=1).max()\n",
    "        start_idx                        = stop_idx\n",
    "    \n",
    "    return np.sqrt(np.sum(distances, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>What So Not</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>2018</td>\n",
       "      <td>electropop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Papa Roach</td>\n",
       "      <td>She Loves Me Not</td>\n",
       "      <td>To Be Loved: The Best Of Papa Roach (Explicit ...</td>\n",
       "      <td>2010</td>\n",
       "      <td>rockhymns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Calvin Logue</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>Warrior EP</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>David Tort</td>\n",
       "      <td>Yo Te Prefiero (feat. Dennisse Jackson)</td>\n",
       "      <td>Yo Te Prefiero (feat. Dennisse Jackson)</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hardwell</td>\n",
       "      <td>Get Low</td>\n",
       "      <td>Get Low</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DNF x I.GOT.U</td>\n",
       "      <td>Sick - Radio Edit</td>\n",
       "      <td>Sick</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>Melody (Tip Of My Tongue)</td>\n",
       "      <td>Melody (Tip Of My Tongue)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dylan Taylor</td>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>Frankenstein</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>James Hype</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>More Than Friends (feat. Kelli-Leigh)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Stadiumx</td>\n",
       "      <td>Spacebird</td>\n",
       "      <td>Spacebird</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_name                                    title  \\\n",
       "33           KSHMR                                  Kolkata   \n",
       "285    What So Not                                Beautiful   \n",
       "461     Papa Roach                         She Loves Me Not   \n",
       "49    Calvin Logue                                  Warrior   \n",
       "58      David Tort  Yo Te Prefiero (feat. Dennisse Jackson)   \n",
       "16        Hardwell                                  Get Low   \n",
       "5    DNF x I.GOT.U                        Sick - Radio Edit   \n",
       "4    Mike Williams                Melody (Tip Of My Tongue)   \n",
       "32    Dylan Taylor                             Frankenstein   \n",
       "13      James Hype    More Than Friends (feat. Kelli-Leigh)   \n",
       "70        Stadiumx                                Spacebird   \n",
       "\n",
       "                                            album_name  year    playlist  \n",
       "33                                             Kolkata  2017   clubbeats  \n",
       "285                                          Beautiful  2018  electropop  \n",
       "461  To Be Loved: The Best Of Papa Roach (Explicit ...  2010   rockhymns  \n",
       "49                                          Warrior EP  2018   clubbeats  \n",
       "58             Yo Te Prefiero (feat. Dennisse Jackson)  2018   clubbeats  \n",
       "16                                             Get Low  2018   clubbeats  \n",
       "5                                                 Sick  2017   clubbeats  \n",
       "4                            Melody (Tip Of My Tongue)  2017   clubbeats  \n",
       "32                                        Frankenstein  2018   clubbeats  \n",
       "13               More Than Friends (feat. Kelli-Leigh)  2017   clubbeats  \n",
       "70                                           Spacebird  2017   clubbeats  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = scaled_eucledian_distance(feature_data, feature_data[query_track_idx])\n",
    "\n",
    "metadata.loc[np.argsort(dist)[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Weighting\n",
    "\n",
    "As explained above, the vanilla Eucliden Distance in an early fusion approach is dominated by large feature-sets. Through scaling the feature-space we achieved equal influence for all feature-sets and features. Now, equal influence is not always the best choice fo music similarity. For example, the year and popularity feature we included into our feature vector are not an intrinsic music property. We just added them to cluster recordings of the same epoch together. Currently this feature has the same impact on the estimated similarity as timbre, rhythm and harmonics. When using many features it is commonly a good choice to apply different weights to them. Estimating these weights is generally achieved empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-set lengths and order\n",
    "featureset_weights = [1.55,  # mfcc\n",
    "                      0.6,  # chroma\n",
    "                      0.8,  # loudness_max\n",
    "                      0.5,  # loudness_start\n",
    "                      0.5,  # loudness_max_time\n",
    "                      2.5,  # sequence length\n",
    "                      0.5,  # confidence\n",
    "                      0.5,  # acousticness\n",
    "                      0.5,  # danceability\n",
    "                      1.5,  # energy\n",
    "                      0.0,  # instrumentalness\n",
    "                      0.0,  # liveness\n",
    "                      0.1,  # speechiness\n",
    "                      0.1,  # tempo\n",
    "                      0.9,  # time_signature\n",
    "                      0.1,  # valence\n",
    "                      5.5,  # year\n",
    "                      0.4]  # popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_eucledian_distance(feature_space, query_vector, featureset_weights):\n",
    "    \n",
    "    distances = (feature_space - query_vector)**2\n",
    "    \n",
    "    # feature_start_idx\n",
    "    start_idx = 0 \n",
    "    \n",
    "    # normalize distances\n",
    "    for sequence_length, weight in zip(featureset_lengths, featureset_weights):\n",
    "\n",
    "        # feature_stop_idx\n",
    "        stop_idx                         = start_idx + sequence_length\n",
    "        distances[:,start_idx:stop_idx] /= distances[:,start_idx:stop_idx].sum(axis=1).max()\n",
    "        distances[:,start_idx:stop_idx] *= weight\n",
    "        start_idx                        = stop_idx\n",
    "\n",
    "    return np.sqrt(np.sum(distances, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>title</th>\n",
       "      <th>album_name</th>\n",
       "      <th>year</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KSHMR</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hardwell</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Safari</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Sparks</td>\n",
       "      <td>Take Me</td>\n",
       "      <td>Take Me</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Galantis</td>\n",
       "      <td>Rich Boy - Quintino Remix</td>\n",
       "      <td>Rich Boy (Remixes)</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maeva Carter</td>\n",
       "      <td>Escape</td>\n",
       "      <td>Escape</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ummet Ozcan</td>\n",
       "      <td>Krypton</td>\n",
       "      <td>Krypton</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Calvin Logue</td>\n",
       "      <td>Warrior</td>\n",
       "      <td>Warrior EP</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bassjackers</td>\n",
       "      <td>Are You Randy?</td>\n",
       "      <td>Are You Randy?</td>\n",
       "      <td>2018</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>What So Not</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>2018</td>\n",
       "      <td>electropop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chimp &amp; Panse</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Mike Williams</td>\n",
       "      <td>Step Up</td>\n",
       "      <td>Step Up</td>\n",
       "      <td>2017</td>\n",
       "      <td>clubbeats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_name                      title          album_name  year  \\\n",
       "33           KSHMR                    Kolkata             Kolkata  2017   \n",
       "36        Hardwell                     Safari              Safari  2018   \n",
       "1      Will Sparks                    Take Me             Take Me  2017   \n",
       "25        Galantis  Rich Boy - Quintino Remix  Rich Boy (Remixes)  2017   \n",
       "22    Maeva Carter                     Escape              Escape  2018   \n",
       "38     Ummet Ozcan                    Krypton             Krypton  2018   \n",
       "49    Calvin Logue                    Warrior          Warrior EP  2018   \n",
       "40     Bassjackers             Are You Randy?      Are You Randy?  2018   \n",
       "285    What So Not                  Beautiful           Beautiful  2018   \n",
       "2    Chimp & Panse                        One                 One  2017   \n",
       "52   Mike Williams                    Step Up             Step Up  2017   \n",
       "\n",
       "       playlist  \n",
       "33    clubbeats  \n",
       "36    clubbeats  \n",
       "1     clubbeats  \n",
       "25    clubbeats  \n",
       "22    clubbeats  \n",
       "38    clubbeats  \n",
       "49    clubbeats  \n",
       "40    clubbeats  \n",
       "285  electropop  \n",
       "2     clubbeats  \n",
       "52    clubbeats  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = weighted_eucledian_distance(feature_data, feature_data[query_track_idx], featureset_weights)\n",
    "\n",
    "metadata.loc[np.argsort(dist)[:11], display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "So far we have only tested our similarity retrieval algorithms on a few single examples. To evaluate, if the presented approaches perform differently, we perform a full evaluation. To estimate the performance we measure precision and recall of our algorithms. These are standard information retrieval measures of relevance. In the context of this tutorial **precision** measures how many tracks of a given resultlist belong to the same playlist as the query song (relative to the length of the resultlist). **Recall** measures how many tracks of the query song's playlist are contained in the resultlist (relative to the length of the playlist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(similarity_function, cut_off):\n",
    "\n",
    "    all_precisions = []\n",
    "    all_recall     = []\n",
    "\n",
    "    for idx in metadata.index.values:\n",
    "\n",
    "        dist           = similarity_function(feature_data, feature_data[idx])\n",
    "        similar_tracks = metadata.loc[np.argsort(dist)[:cut_off]]\n",
    "        same_label     = similar_tracks[\"playlist\"] == metadata.loc[idx, \"playlist\"]\n",
    "        precision      = same_label.sum() / float(cut_off)\n",
    "        all_precisions.append(precision)\n",
    "        \n",
    "        recall = float(same_label.sum()) / metadata[metadata.playlist == metadata.loc[idx, \"playlist\"]].shape[0]\n",
    "        all_recall.append(recall)\n",
    "\n",
    "    all_precisions = np.array(all_precisions)\n",
    "    all_recall     = np.array(recall)\n",
    "\n",
    "    return all_precisions.mean(), all_recall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the evauation for all three introduced algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weighted Eucledian Distance</th>\n",
       "      <td>0.609009</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scaled Eucledian Distance</th>\n",
       "      <td>0.534387</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eucledian Distance</th>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             precision  recall\n",
       "Weighted Eucledian Distance   0.609009     0.2\n",
       "Scaled Eucledian Distance     0.534387     0.2\n",
       "Eucledian Distance            0.472028     0.2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off = 20\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "# run evaluation\n",
    "\n",
    "evaluation_results[\"Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: eucledian_distance(x,y), cut_off)\n",
    "    \n",
    "\n",
    "evaluation_results[\"Scaled Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: scaled_eucledian_distance(x,y), cut_off)\n",
    "\n",
    "evaluation_results[\"Weighted Eucledian Distance\"] = \\\n",
    "    evaluate(lambda x,y: weighted_eucledian_distance(x,y, featureset_weights), cut_off)\n",
    "\n",
    "# aggregate results\n",
    "evaluation_results = pd.DataFrame(data  = [evaluation_results[key] for key in evaluation_results.keys()], \n",
    "                                  index = evaluation_results.keys(), \n",
    "                                  columns=[\"precision\", \"recall\"])\n",
    "\n",
    "# results\n",
    "evaluation_results.sort_values(\"precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results must be interpreted in relation to the analyzed data-set and the method how the metrics are measured. We measure how many tracks in the resulting list of similar songs belong to the same playlist of the query song. We have chosen genre-related playlists such as *Metal* and *Hip-Hop*. But there are also overalpping playlists such as *Classic Metal* and *Rock Hymns* which both contain Rock and Metal tracks. This should be considered in the interpretation of the evaluation results. To get more reliable results, more efforts need to be put into creating better non-overlapping playlists. But, since music similarity is subject to subjective interpretation, this is a challinging task.\n",
    "\n",
    "Although we have a small bias from the overlapping playlists, we see that it makes sense to tune the weights of the features to regulate their impact on the final results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this part of the tutorial I have demonstrated how to access the Spotify to download meta- and feature-data to estimate similarities between songs. The presented method is a content-based approach which calculate similarities based on numerical vector distances.\n",
    "\n",
    "The approach has been chosen due to its simplicity. There is a lot of room for improvements, but this would have made the code examples more complex and the tutorial much longer. To improve the performance, you can consider the following improvements:\n",
    "\n",
    "* **Feature aggregation:** taking only mean and standard deviation is not the most efficient way to aggregate the sequential features provided by the Spotify API.\n",
    "* **Distance Measure:** other distance measures could yield better results. This often depends on the underlying dataset.\n",
    "* **Better Machine Learning Methods:** the presented nearest neighobr based approach is a linear model and is not able to model non-linearities of music similarities.\n",
    "\n",
    "In the next part of this tutorial series I will introduce Siamese Netowkrs. These Deep Neural Networks are able to learn high-level features from the low-level features as well as to learn the non-linear distance function to estimate the similarity between two tracks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "5",
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
